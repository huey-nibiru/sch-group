{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('SCHGROUP_data.csv')\n",
    "\n",
    "# Filter the data for billable hours only\n",
    "df = df[df[\"BillType\"] == \"Billable\"]\n",
    "\n",
    "# Convert the Date column to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filter the data by year\n",
    "df_2019 = df[df['Date'].dt.year == 2019]\n",
    "df_2020 = df[df['Date'].dt.year == 2020]\n",
    "df_2021 = df[df['Date'].dt.year == 2021]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which department had the most billable hours in 2019, 2020, and 2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The department with the most billable hours in 2019 was TAS - Audit.\n",
      "The department with the most billable hours in 2020 was TAS - Audit.\n",
      "The department with the most billable hours in 2021 was TAS - Audit.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Group the data by department and sum the Hours column\n",
    "hours_2019 = df_2019.groupby('DeptName')['Hours'].sum()\n",
    "\n",
    "hours_2020 = df_2020.groupby('DeptName')['Hours'].sum()\n",
    "hours_2021 = df_2021.groupby('DeptName')['Hours'].sum()\n",
    "\n",
    "# Find the department with the highest billable hours in each year\n",
    "max_dept_2019 = hours_2019.idxmax()\n",
    "max_dept_2020 = hours_2020.idxmax()\n",
    "max_dept_2021 = hours_2021.idxmax()\n",
    "\n",
    "# Sort by Hours\n",
    "h2019=hours_2019.reset_index().sort_values(by='Hours', ascending=False)\n",
    "h2020=hours_2020.reset_index().sort_values(by='Hours', ascending=False)\n",
    "h2021=hours_2021.reset_index().sort_values(by='Hours', ascending=False)\n",
    "\n",
    "print(f\"The department with the most billable hours in 2019 was {max_dept_2019}.\")\n",
    "print(f\"The department with the most billable hours in 2020 was {max_dept_2020}.\")\n",
    "print(f\"The department with the most billable hours in 2021 was {max_dept_2021}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which client had the highest total billable amount in each year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year ClientNum                                        TotalAmount\n",
      "0  2019   CLT1579  $992.06 $981.34 $130.85 $79.37 $1,226.67 $636....\n",
      "1  2020   CLT3705  $997.43 $83.12 $83.12 $262.76 $249.36 $494.15 ...\n",
      "2  2021   CLT3199  $992.06 $589.88 $268.13 $375.38 $1,126.13 $321...\n"
     ]
    }
   ],
   "source": [
    "# convert Date column to datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# create a new column for the year\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# group the dataset by Year and ClientNum, and calculate the sum of TotalAmount\n",
    "grouped_df = df.groupby(['Year', 'ClientNum'])['TotalAmount'].sum().reset_index()\n",
    "\n",
    "# sort the dataframe by TotalAmount in descending order\n",
    "sorted_df = grouped_df.sort_values(['Year', 'TotalAmount'], ascending=[True, False])\n",
    "\n",
    "# select the top row for each year\n",
    "result = sorted_df.groupby('Year').first().reset_index()\n",
    "\n",
    "# print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the average billable rate for each department over the three years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/gf09nxpx12n_7pcjsnlx5yt00000gn/T/ipykernel_6022/3451522396.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_2019['BillRate'] = df_2019['BillRate'].str.replace('$', '')\n",
      "/var/folders/fm/gf09nxpx12n_7pcjsnlx5yt00000gn/T/ipykernel_6022/3451522396.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019['BillRate'] = df_2019['BillRate'].str.replace('$', '')\n",
      "/var/folders/fm/gf09nxpx12n_7pcjsnlx5yt00000gn/T/ipykernel_6022/3451522396.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019['BillRate'] = df_2019['BillRate'].str.strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['327.11' '316.39' '0.62' '445.09' '402.19' '509.44' '262.76' '396.83'\n",
      " '137.28' '268.13' '166.24' '622.05' '530.89' '219.86' '246.68' '-'\n",
      " '241.31' '0.58' '348.56' '294.94' '337.84' '455.81' '536.25' '332.48'\n",
      " '214.50' '264.96' '447.23' '513.73' '210.21' '407.55' '187.69' '107.20'\n",
      " '253.11' '381.81' '480.48' '261.69' '209.14' '356.07' '321.75' '236.49'\n",
      " '400.58' '386.10' '124.41' '458.49' '155.51' '315.32' '450.45' '237.29'\n",
      " '321.43' '277.78' '357.95' '420.42' '150.15' '134.06' '310.22' '297.62'\n",
      " '333.82' '245.33' '182.33' '382.08' '514.80' '228.98' '197.07' '469.76'\n",
      " '284.21' '198.41' '160.88' '176.96' '317.46' '203.78' '132.72' '311.56'\n",
      " '107.25' '1.07' '402.40' '211.98' '319.77' '356.61' '429.00' '289.31'\n",
      " '212.62' '183.93' '117.98' '235.95' '390.39' '205.65' '230.59' '115.03'\n",
      " '163.02' '243.46' '128.70' '313.49' '193.05' '278.85' '250.70' '387.44'\n",
      " '225.23' '123.34' '336.77' '81.51' '257.40' '252.04' '205.12' '296.28'\n",
      " '155.38' '61.13' '31.72' '357.12' '158.73' '600.60' '331.13' '294.40'\n",
      " '233.81' '375.38' '154.44' '121.19' '220.94' '152.30' '24.67' '17.16'\n",
      " '418.28' '319.61' '17.60' '197.34' '171.60' '45.85' '187.39' '141.57'\n",
      " '434.36' '120.92' '402.46' '412.64' '723.94' '15.02' '405.67' '143.72'\n",
      " '504.50' '357.79' '185.01' '520.16' '268.93' '148.01' '42.80' '106.18'\n",
      " '170.80' '120.12' '477.26' '427.80' '38.57' '392.67' '123.87' '212.84'\n",
      " '71.51' '11.36' '139.43' '113.77' '441.87' '98.67' '334.08' '765.25'\n",
      " '360.36' '21.45' '364.65' '144.79' '527.88' '342.34' '462.20' '319.56'\n",
      " '53.09' '29.86' '63.82' '25.99' '210.42' '31.91' '326.04' '33.59'\n",
      " '803.57' '28.96' '343.20' '7.61' '390.12' '44.79' '19.33' '132.37'\n",
      " '20.13' '5.95' '2.38' '29.13' '18.53' '13.15' '15.00' '41.06' '37.08'\n",
      " '14.31' '409.17' '1,177.51' '7.69' '64.33' '255.65' '416.13' '454.47'\n",
      " '509.01' '6.47' '546.98' '84.51' '249.36' '264.91' '31.10' '421.33'\n",
      " '330.12' '17.73' '30.48' '13.14' '285.29' '265.98' '305.66' '346.85'\n",
      " '42.85' '502.52' '309.68' '466.54' '189.03' '12.87' '424.17' '289.04'\n",
      " '361.97' '323.36' '364.11' '484.77' '330.33' '313.71' '299.23' '49.34'\n",
      " '405.99' '393.88' '83.66' '254.13' '111.54' '18,031.69' '468.15'\n",
      " '32,175.00' '112.61' '195.20' '270.27' '167.31' '605.96' '27.89' '341.86'\n",
      " '55.77' '3,252.45' '405.41' '6,031.47' '265.44' '808.67' '223.08'\n",
      " '365.51' '117.87' '91.16' '75.08' '289.58' '85.80' '69.71' '101.89'\n",
      " '9.97' '353.93']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert -- to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1774\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1774\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49m_cython_operation(\n\u001b[1;32m   1775\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39maggregate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1776\u001b[0m         values,\n\u001b[1;32m   1777\u001b[0m         how,\n\u001b[1;32m   1778\u001b[0m         axis\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1779\u001b[0m         min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m   1780\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1781\u001b[0m     )\n\u001b[1;32m   1782\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1783\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:1040\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m ngroups \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngroups\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mreturn\u001b[39;00m cy_op\u001b[39m.\u001b[39;49mcython_operation(\n\u001b[1;32m   1041\u001b[0m     values\u001b[39m=\u001b[39;49mvalues,\n\u001b[1;32m   1042\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   1043\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m   1044\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m   1045\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m   1046\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1047\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:708\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[1;32m    701\u001b[0m         values,\n\u001b[1;32m    702\u001b[0m         min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    706\u001b[0m     )\n\u001b[0;32m--> 708\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_op_ndim_compat(\n\u001b[1;32m    709\u001b[0m     values,\n\u001b[1;32m    710\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    711\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    712\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[1;32m    713\u001b[0m     mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    714\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    715\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:512\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m     result_mask \u001b[39m=\u001b[39m result_mask[\u001b[39mNone\u001b[39;00m, :]\n\u001b[0;32m--> 512\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_cython_op(\n\u001b[1;32m    513\u001b[0m     values2d,\n\u001b[1;32m    514\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m    515\u001b[0m     ngroups\u001b[39m=\u001b[39;49mngroups,\n\u001b[1;32m    516\u001b[0m     comp_ids\u001b[39m=\u001b[39;49mcomp_ids,\n\u001b[1;32m    517\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    518\u001b[0m     result_mask\u001b[39m=\u001b[39;49mresult_mask,\n\u001b[1;32m    519\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    521\u001b[0m \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:571\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[0;32m--> 571\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cython_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkind, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow, values\u001b[39m.\u001b[39;49mdtype, is_numeric)\n\u001b[1;32m    572\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:192\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39m__signatures__:\n\u001b[1;32m    191\u001b[0m     \u001b[39m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    193\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction is not implemented for this dtype: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mdtype_str\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:1630\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1630\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[1;32m   1631\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1632\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '--'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:1634\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1634\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[1;32m   1635\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1636\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mBillRate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39mBillRate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(df_2019[\u001b[39m'\u001b[39m\u001b[39mBillRate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())\n\u001b[0;32m---> 20\u001b[0m billable_rates \u001b[39m=\u001b[39m df_2019\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mDeptID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mBillType\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m'\u001b[39;49m\u001b[39mBillRate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39munstack()[\u001b[39m'\u001b[39m\u001b[39mBillable\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:2161\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   2160\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2161\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_agg_general(\n\u001b[1;32m   2162\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2163\u001b[0m         alt\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only_bool),\n\u001b[1;32m   2164\u001b[0m         numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[1;32m   2165\u001b[0m     )\n\u001b[1;32m   2166\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1793\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m   1789\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m   1791\u001b[0m \u001b[39m# TypeError -> we may have an exception in trying to aggregate\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \u001b[39m#  continue and exclude the block\u001b[39;00m\n\u001b[0;32m-> 1793\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgrouped_reduce(array_func, ignore_failures\u001b[39m=\u001b[39;49mignore_failures)\n\u001b[1;32m   1795\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ser \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(new_mgr) \u001b[39m<\u001b[39m orig_len:\n\u001b[1;32m   1796\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), how, numeric_only)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/internals/base.py:199\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39mignore_failures : bool, default False\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m    Not used; for compatibility with ArrayManager/BlockManager.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marray\n\u001b[0;32m--> 199\u001b[0m res \u001b[39m=\u001b[39m func(arr)\n\u001b[1;32m    200\u001b[0m index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(res))\n\u001b[1;32m    202\u001b[0m mgr \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1787\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1774\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39m_cython_operation(\n\u001b[1;32m   1775\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1776\u001b[0m         values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1781\u001b[0m     )\n\u001b[1;32m   1782\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1783\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m-> 1787\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim, alt\u001b[39m=\u001b[39;49malt)\n\u001b[1;32m   1789\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1728\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1723\u001b[0m     ser \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m   1725\u001b[0m \u001b[39m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m \u001b[39m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m \u001b[39m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[0;32m-> 1728\u001b[0m res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, Categorical):\n\u001b[1;32m   1731\u001b[0m     \u001b[39m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m     \u001b[39m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m     \u001b[39m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(values)\u001b[39m.\u001b[39m_from_sequence(res_values, dtype\u001b[39m=\u001b[39mvalues\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:1082\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m   1084\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/ops.py:1105\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1102\u001b[0m splitter \u001b[39m=\u001b[39m get_splitter(obj, ids, ngroups, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1104\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1105\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m   1106\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[1;32m   1108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[1;32m   1109\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:2163\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[1;32m   2160\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2161\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2162\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m-> 2163\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only_bool),\n\u001b[1;32m   2164\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[1;32m   2165\u001b[0m     )\n\u001b[1;32m   2166\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/generic.py:11856\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11838\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11839\u001b[0m     _num_doc,\n\u001b[1;32m  11840\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11854\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11855\u001b[0m ):\n\u001b[0;32m> 11856\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/generic.py:11408\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11400\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11401\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11402\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11406\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11407\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11408\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11409\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11410\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/generic.py:11360\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m  11351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11352\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11355\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m  11356\u001b[0m     )\n\u001b[1;32m  11357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11358\u001b[0m         name, axis\u001b[39m=\u001b[39maxis, level\u001b[39m=\u001b[39mlevel, skipna\u001b[39m=\u001b[39mskipna, numeric_only\u001b[39m=\u001b[39mnumeric_only\n\u001b[1;32m  11359\u001b[0m     )\n\u001b[0;32m> 11360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11361\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11362\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/series.py:4819\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4816\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not implement \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4817\u001b[0m     )\n\u001b[1;32m   4818\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4819\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tickpick/lib/python3.10/site-packages/pandas/core/nanops.py:1637\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[1;32m   1635\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1636\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1637\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert -- to numeric"
     ]
    }
   ],
   "source": [
    "df_2019\n",
    "# group the data by department and bill type, and calculate the average billable rate\n",
    "#billable_rate_2019 = df_2019.groupby(['DeptID', 'BillType'])['BillRate'].mean().unstack()['Billable']\n",
    "\n",
    "# print the result\n",
    "#print(billable_rate_2019)\n",
    "# replace all \"$\" characters in the \"BillRate\" column with empty string\n",
    "df_2019['BillRate'] = df_2019['BillRate'].str.replace('$', '')\n",
    "df_2019['BillRate'] = df_2019['BillRate'].str.strip()\n",
    "\n",
    "# replace all non-numeric characters in the \"BillRate\" column with 0\n",
    "df['BillRate'] = df['BillRate'].str.replace('[^0-9\\.]', '0', regex=True)\n",
    "\n",
    "# convert the \"BillRate\" column to numeric type\n",
    "df['BillRate'] = pd.to_numeric(df['BillRate'])\n",
    "\n",
    "\n",
    "print(df_2019['BillRate'].unique())\n",
    "\n",
    "billable_rates = df_2019.groupby(['DeptID', 'BillType'])['BillRate'].mean().unstack()['Billable']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many different clients used the company's services over the three years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3049\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique clients in the dataset\n",
    "num_clients = len(df['ClientNum'].unique())\n",
    "\n",
    "print(num_clients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which employee billed the most hours in each year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of billable hours for each employee in each year\n",
    "employee_hours = df.groupby(['EmployeeId', 'Date'])['Hours'].sum()\n",
    "\n",
    "# Find the employee with the highest billable hours for each year\n",
    "highest_employee_hours = employee_hours.groupby('Date').idxmax()\n",
    "\n",
    "print(highest_employee_hours.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which department had the highest total billable amount in each year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of total amount for each department in each year\n",
    "total_amount = df.groupby(['DeptName', 'Date'])['TotalAmount'].sum()\n",
    "\n",
    "# Find the department with the highest total amount for each year\n",
    "highest_dept_amount = total_amount.groupby('Date').idxmax()\n",
    "\n",
    "print(highest_dept_amount)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the overall trend in billable hours and billable amount over the three years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the sum of billable hours and total amount for each year\n",
    "yearly_summary = df.groupby('Date').agg({'Hours': 'sum', 'TotalAmount': 'sum'})\n",
    "\n",
    "# Plot the trend in billable hours and total amount over the three years\n",
    "yearly_summary.plot(kind='line')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the total amount billed by each employee in each year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of total amount for each employee in each year\n",
    "employee_amount = df.groupby(['EmployeeId', 'Date'])['TotalAmount'].sum()\n",
    "\n",
    "print(employee_amount)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the distribution of billable rates across all departments?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of billable rates across all departments\n",
    "sns.histplot(data=df, x='BillRate', hue='DeptName')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the average billable rate for each client over the three years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean billable rate for each client in each year\n",
    "mean_billable_rate = df.groupby(['ClientNum', 'Date'])['BillRate'].mean()\n",
    "\n",
    "print(mean_billable_rate)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clients who consistently have high or low billable rates?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of billable rates for each client over the three years\n",
    "std_billable_rate = df.groupby(['ClientNum'])['BillRate'].std()\n",
    "\n",
    "# Find the clients with the highest and lowest standard deviation\n",
    "highest_std_clients = std_billable_rate.nlargest(5)\n",
    "lowest_std_clients = std_billable_rate.nsmallest(5)\n",
    "\n",
    "print(highest_std_clients)\n",
    "print(lowest_std_clients)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Departments or employees that consistently underperform in terms of billable hours or billable amount?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean billable hours and total amount for each department and employee\n",
    "dept_hours_amount = df.groupby(['DeptName'])[['Hours', 'TotalAmount']].mean()\n",
    "employee_hours_amount = df.groupby(['EmployeeId'])[['Hours', 'TotalAmount']].mean()\n",
    "\n",
    "# Find the departments and employees with the lowest mean billable hours and total amount\n",
    "lowest_dept_hours = dept_hours_amount.nsmallest(5, 'Hours')\n",
    "lowest_dept_amount = dept_hours_amount.nsmallest(5, 'TotalAmount')\n",
    "lowest_employee_hours = employee_hours_amount.nsmallest(5, 'Hours')\n",
    "lowest_employee_amount = employee_hours_amount.nsmallest(5, 'TotalAmount')\n",
    "\n",
    "print(lowest_dept_hours)\n",
    "print(lowest_dept_amount)\n",
    "print(lowest_employee_hours)\n",
    "print(lowest_employee_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many different departments are represented in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique departments in the dataset\n",
    "num_departments = len(df['DeptName'].unique())\n",
    "\n",
    "print(num_departments)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the ratio of billable hours to total hours worked by each employee in each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio of billable hours to total hours for each employee in each year\n",
    "employee_ratio = df.groupby(['EmployeeId', 'Date']).apply(lambda x: x[x['BillType'] == 'Billable']['Hours'].sum() / x['Hours'].sum())\n",
    "\n",
    "print(employee_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the overall distribution of billable hours and billable amount across all clients and departments?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of billable hours and total amount across all clients and departments\n",
    "sns.histplot(data=df, x='Hours', hue='DeptName')\n",
    "sns.histplot(data=df, x='TotalAmount', hue='DeptName')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
